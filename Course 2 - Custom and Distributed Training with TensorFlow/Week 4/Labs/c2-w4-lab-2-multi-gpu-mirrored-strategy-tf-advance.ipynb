{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":30747,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Multi-GPU Mirrored Strategy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"import tensorflow as tf\nimport numpy as np\nimport os\n# Note that it generally has a minimum of 8 cores, but if your GPU has\n# less, you need to set this. In this case one of my GPUs has 4 cores\nos.environ[\"TF_MIN_GPU_MULTIPROCESSOR_COUNT\"] = \"4\"\n\n# If the list of devices is not specified in the\n# `tf.distribute.MirroredStrategy` constructor, it will be auto-detected.\n# If you have *different* GPUs in your system, you probably have to set up cross_device_ops like this\nstrategy = tf.distribute.MirroredStrategy(cross_device_ops=tf.distribute.HierarchicalCopyAllReduce())\nprint ('Number of devices: {}'.format(strategy.num_replicas_in_sync))\n\n\n# Get the data\nfashion_mnist = tf.keras.datasets.fashion_mnist\n(train_images, train_labels), (test_images, test_labels) = fashion_mnist.load_data()\n\n# Adding a dimension to the array -> new shape == (28, 28, 1)\n# We are doing this because the first layer in our model is a convolutional\n# layer and it requires a 4D input (batch_size, height, width, channels).\n# batch_size dimension will be added later on.\ntrain_images = train_images[..., None]\ntest_images = test_images[..., None]\n\n# Normalize the images to [0, 1] range.\ntrain_images = train_images / np.float32(255)\ntest_images = test_images / np.float32(255)\n\n# Batch the input data\nBUFFER_SIZE = len(train_images)\nBATCH_SIZE_PER_REPLICA = 64\nGLOBAL_BATCH_SIZE = BATCH_SIZE_PER_REPLICA * strategy.num_replicas_in_sync\n\n# Create Datasets from the batches\ntrain_dataset = tf.data.Dataset.from_tensor_slices((train_images, train_labels)).shuffle(BUFFER_SIZE).batch(GLOBAL_BATCH_SIZE)\ntest_dataset = tf.data.Dataset.from_tensor_slices((test_images, test_labels)).batch(GLOBAL_BATCH_SIZE)\n\n# Create Distributed Datasets from the datasets\ntrain_dist_dataset = strategy.experimental_distribute_dataset(train_dataset)\ntest_dist_dataset = strategy.experimental_distribute_dataset(test_dataset)\n\n# Create the model architecture\ndef create_model():\n  model = tf.keras.Sequential([\n      tf.keras.layers.Conv2D(32, 3, activation='relu'),\n      tf.keras.layers.MaxPooling2D(),\n      tf.keras.layers.Conv2D(64, 3, activation='relu'),\n      tf.keras.layers.MaxPooling2D(),\n      tf.keras.layers.Flatten(),\n      tf.keras.layers.Dense(64, activation='relu'),\n      tf.keras.layers.Dense(10)\n    ])\n  return model\n\n# Instead of model.compile, we're going to do custom training, so let's do that\n# within a strategy scope\nwith strategy.scope():\n    # We will use sparse categorical crossentropy as always. But, instead of having the loss function\n    # manage the map reduce across GPUs for us, we'll do it ourselves with a simple algorithm.\n    # Remember -- the map reduce is how the losses get aggregated\n    # Set reduction to `none` so we can do the reduction afterwards and divide byglobal batch size.\n    loss_object = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True, reduction=tf.keras.losses.Reduction.NONE)\n\n    def compute_loss(labels, predictions):\n        # Compute Loss uses the loss object to compute the loss\n        # Notice that per_example_loss will have an entry per GPU\n        # so in this case there'll be 2 -- i.e. the loss for each replica\n        per_example_loss = loss_object(labels, predictions)\n        # You can print it to see it -- you'll get output like this:\n        # Tensor(\"sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\n        # Tensor(\"replica_1/sparse_categorical_crossentropy/weighted_loss/Mul:0\", shape=(48,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:1)\n        # Note in particular that replica_0 isn't named in the weighted_loss -- the first is unnamed, the second is replica_1 etc\n        print(per_example_loss)\n        return tf.nn.compute_average_loss(per_example_loss, global_batch_size=GLOBAL_BATCH_SIZE)\n\n    # We'll just reduce by getting the average of the losses\n    test_loss = tf.keras.metrics.Mean(name='test_loss')\n\n    # Accuracy on train and test will be SparseCategoricalAccuracy\n    train_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='train_accuracy')\n    test_accuracy = tf.keras.metrics.SparseCategoricalAccuracy(name='test_accuracy')\n\n    # Optimizer will be Adam\n    optimizer = tf.keras.optimizers.Adam()\n\n    # Create the model within the scope\n    model = create_model()\n\n\n###########################\n# Training Steps Functions\n###########################\n\n# `run` replicates the provided computation and runs it\n# with the distributed input.\n@tf.function\ndef distributed_train_step(dataset_inputs):\n  per_replica_losses = strategy.run(train_step, args=(dataset_inputs,))\n  #tf.print(per_replica_losses.values)\n  return strategy.reduce(tf.distribute.ReduceOp.SUM, per_replica_losses, axis=None)\n\ndef train_step(inputs):\n  images, labels = inputs\n  with tf.GradientTape() as tape:\n    predictions = model(images, training=True)\n    loss = compute_loss(labels, predictions)\n\n  gradients = tape.gradient(loss, model.trainable_variables)\n  optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n\n  train_accuracy.update_state(labels, predictions)\n  return loss\n\n#######################\n# Test Steps Functions\n#######################\n@tf.function\ndef distributed_test_step(dataset_inputs):\n  return strategy.run(test_step, args=(dataset_inputs,))\n\ndef test_step(inputs):\n  images, labels = inputs\n\n  predictions = model(images, training=False)\n  t_loss = loss_object(labels, predictions)\n\n  test_loss.update_state(t_loss)\n  test_accuracy.update_state(labels, predictions)\n\n\n###############\n# TRAINING LOOP\n###############\n\nEPOCHS = 10\nfor epoch in range(EPOCHS):\n  # Do Training\n  total_loss = 0.0\n  num_batches = 0\n  for batch in train_dist_dataset:\n    total_loss += distributed_train_step(batch)\n    num_batches += 1\n  train_loss = total_loss / num_batches\n\n  # Do Testing\n  for batch in test_dist_dataset:\n    distributed_test_step(batch)\n\n  template = (\"Epoch {}, Loss: {}, Accuracy: {}, Test Loss: {}, \" \"Test Accuracy: {}\")\n\n  print (template.format(epoch+1, train_loss, train_accuracy.result()*100, test_loss.result(), test_accuracy.result()*100))\n\n  test_loss.reset_states()\n  train_accuracy.reset_states()\n  test_accuracy.reset_states()","metadata":{"execution":{"iopub.status.busy":"2024-07-22T14:01:58.251525Z","iopub.execute_input":"2024-07-22T14:01:58.251914Z","iopub.status.idle":"2024-07-22T14:02:26.798993Z","shell.execute_reply.started":"2024-07-22T14:01:58.251883Z","shell.execute_reply":"2024-07-22T14:02:26.797680Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stderr","text":"2024-07-22 14:02:00.057385: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-07-22 14:02:00.057483: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-07-22 14:02:00.203546: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"name":"stdout","text":"Number of devices: 1\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\nDownloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\nTensor(\"sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\nTensor(\"sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:0\", shape=(64,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\nTensor(\"sparse_categorical_crossentropy/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits:0\", shape=(32,), dtype=float32, device=/job:localhost/replica:0/task:0/device:GPU:0)\nEpoch 1, Loss: 0.5069535970687866, Accuracy: 81.69166564941406, Test Loss: 0.3897673487663269, Test Accuracy: 86.02999877929688\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","Cell \u001b[0;32mIn[1], line 154\u001b[0m\n\u001b[1;32m    150\u001b[0m template \u001b[38;5;241m=\u001b[39m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEpoch \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Accuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, Test Loss: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTest Accuracy: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    152\u001b[0m \u001b[38;5;28mprint\u001b[39m (template\u001b[38;5;241m.\u001b[39mformat(epoch\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m, train_loss, train_accuracy\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m, test_loss\u001b[38;5;241m.\u001b[39mresult(), test_accuracy\u001b[38;5;241m.\u001b[39mresult()\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m100\u001b[39m))\n\u001b[0;32m--> 154\u001b[0m \u001b[43mtest_loss\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreset_states\u001b[49m()\n\u001b[1;32m    155\u001b[0m train_accuracy\u001b[38;5;241m.\u001b[39mreset_states()\n\u001b[1;32m    156\u001b[0m test_accuracy\u001b[38;5;241m.\u001b[39mreset_states()\n","\u001b[0;31mAttributeError\u001b[0m: 'Mean' object has no attribute 'reset_states'"],"ename":"AttributeError","evalue":"'Mean' object has no attribute 'reset_states'","output_type":"error"}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}